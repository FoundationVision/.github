# Welcome to FoundationVision @ ByteDance!

## Introduction ðŸ‘‹

Hello! This is the GitHub space for the **FoundationVision @ ByteDance**.

We are dedicated to **exploring the frontiers of multimodal intelligence, with the ultimate goal of building Artificial General Intelligence systems (AGI)**.

Our research focuses on **deep learning and multimodal intelligence**. We are particularly interested in:
* Visual Foundation Models, Generative Pretrained Models and Large Language Models.
* Multimodal Foundation Models and Representation Learning.
* Open World Interaction via Unified Multi-modal generation and understanding.
* Large-scale Multi-modal generative Pretraining and Alignment.

Our group strives to push the boundaries of multimodal intelligence and has produced highly influential works in the field, including:
* **Generative Models**: [VAR](https://github.com/FoundationVision/VAR), [Waver](https://github.com/FoundationVision/Waver), [Infinity](https://github.com/FoundationVision/Infinity), [LLamaGen](https://github.com/FoundationVision/LLamaGen), [InfinityStar](https://github.com/FoundationVision/InfinityStar), [OmniTokenizer](https://github.com/FoundationVision/OmniTokenizer)
* **Object Recognition and Representation Learning**: [Sparse-RCNN](https://github.com/PeizeSun/SparseR-CNN), [ByteTrack](https://github.com/FoundationVision/ByteTrack), [SparK](https://github.com/keyu-tian/SparK), [UNINEXT](https://github.com/MasterBin-IIAU/UNINEXT), [Unicorn](https://github.com/MasterBin-IIAU/Unicorn), [DanceTrack](https://github.com/DanceTrack/DanceTrack), [VNext](https://github.com/FoundationVision/VNext), [Referformer](https://github.com/wjn922/ReferFormer)
* **Multimodal Foundation Models**: [Groma](https://github.com/FoundationVision/Groma), [Liquid](https://github.com/FoundationVision/Liquid), [UniTok](https://github.com/FoundationVision/UniTok), [GLEE](https://github.com/FoundationVision/GLEE)




