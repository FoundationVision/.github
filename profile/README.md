# Welcome to FoundationVision @ ByteDance!

## Introduction ðŸ‘‹

Hello! This is the GitHub space for the **FoundationVision @ ByteDance**.

We are dedicated to **exploring the frontiers of multimodal intelligence, with the ultimate goal of constructing Artificial General Intelligence (AGI)**.

Our research focuses on **deep learning and multimodal intelligence**. We are particularly interested in:
* Visual Foundation Models, Generative Pretrain Models and Large Language Models.
* Multimodal Foundation Models and Representation Learning
* Open World Interaction via Unified Multi-modal generation and understanding.
* Large-scale Multi-modal generative Pretraining and Alignment.


Our group strives to push the boundaries of multimodal intelligence and has produced highly influential works in the field, including [VAR](https://github.com/FoundationVision/VAR), [Waver](https://github.com/FoundationVision/Waver), [Infinity](https://github.com/FoundationVision/Infinity), [ByteTrack](https://github.com/FoundationVision/ByteTrack), [LLamaGen](https://github.com/FoundationVision/LLamaGen), [Sparse-RCNN](https://github.com/PeizeSun/SparseR-CNN), [SparK](https://github.com/keyu-tian/SparK), [UNINEXT](https://github.com/MasterBin-IIAU/UNINEXT), [Groma](https://github.com/FoundationVision/Groma), [Liquid](https://github.com/FoundationVision/Liquid), [UniTok](https://github.com/FoundationVision/UniTok), [GLEE](https://github.com/FoundationVision/GLEE), and [InfinityStar](https://github.com/FoundationVision/InfinityStar).




